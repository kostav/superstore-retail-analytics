{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd9e3a1-98ec-45ef-be82-15a6c8fdb7d7",
   "metadata": {},
   "source": [
    "# SECTION 0: DATA CLEANING OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6dc25d-4f60-45b6-ac55-4bb23b1c4786",
   "metadata": {},
   "source": [
    "Τhis section is responsible for the data cleaning process needed in order to have a valid data set for our analysis in the next sections. Prior to this step we had already run a set of SQL queries in order to validate:\n",
    "\n",
    "1. **Null counts** on critical columns (Order Date, Region, Category, Profit, Discount)\n",
    "2. **Invalid discount values** outside the [0, 1] range \n",
    "3. **Potential duplicates** at the (Order ID, Customer ID, Product ID) level\n",
    "4. **Distinct categorical values** to check for spelling or formatting issues\n",
    "\n",
    "The SQL script is stored in: `sql/superstore_data_integrity_checks.sql`\n",
    "\n",
    "**⇒** Below we present all the steps of the Python data cleaning pipeline:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a88e5b-251b-4548-a477-a3be32587be7",
   "metadata": {},
   "source": [
    "---\n",
    "### i) Datetime Conversion\n",
    "- Converts `order_date`, `ship_date` to proper datetime format.\n",
    "- Coerces invalid strings to NaT (Not a Time, i.e.missing value for dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5755217c-41fb-4c51-a8bd-439f186dd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"order_date\",\"ship_date\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad8cdc-9ca4-4e8c-898f-ba7cb311c9c8",
   "metadata": {},
   "source": [
    "---\n",
    "### ii) Numeric Fields\n",
    "- Ensures numeric columns (`sales`, `profit`, `discount`) are floats/ints.\n",
    "- Coerces invalid entries to NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826c6d56-cb29-4502-95b5-ee7148be5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"sales\",\"profit\",\"discount\",\"quantity\",\"postal_code\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec1787-6a38-4cdd-86a2-15111d6ef28e",
   "metadata": {},
   "source": [
    "---\n",
    "### iii) Boundary Rules\n",
    "- Flags absurd values such as negative sales and unrealisticly profit/loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "058e5c04-d9b0-4957-8671-26042daf489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with sales <= 0: 0\n",
      "Rows with |profit| > 100000: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with sales <= 0:\", int((df['sales'] <= 0).sum()))\n",
    "print(\"Rows with |profit| > 100000:\", int((df['profit'].abs() > 100000).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ff3d9-7f8f-4346-ba22-978dedd7d7f8",
   "metadata": {},
   "source": [
    "---\n",
    "### iv) Column Normalization\n",
    "- Normalize columns names to drop capital letters etc and have all data names in a unified way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e70446d-8b70-4d6e-bf3c-46f76a4eb7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Column Names:  ['row_id', 'order_id', 'order_date', 'ship_date', 'ship_mode', 'customer_id', 'customer_name', 'segment', 'country', 'city', 'state', 'postal_code', 'region', 'product_id', 'category', 'sub_category', 'product_name', 'sales', 'quantity', 'discount', 'profit']\n"
     ]
    }
   ],
   "source": [
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(\" \", \"_\")\n",
    "      .str.replace(\"-\", \"_\")\n",
    ")\n",
    "\n",
    "print(\"Dataset Column Names: \", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f57b0-1bc0-4a31-b009-1fca69b14349",
   "metadata": {},
   "source": [
    "---\n",
    "### v) Clean Dataset Exportation\n",
    "- Export the clean dataset in a pro in order to run the next data analysis steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874aa1b4-1d22-416d-8577-8cf88b1b0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "df_clean.to_pickle(\"clean_superstore.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
